import argparse, logging, datetime, signal
import time

import psycopg2
import z3

int_type = "enc_int4"
float_type = "enc_float4"
str_type = "enc_text"
timestamp_type = "enc_timestamp"

data_types = {
    int_type : "enc_int4_decrypt",
    float_type : "enc_float4_decrypt",
    str_type : "enc_text_decrypt",
    timestamp_type : "enc_timestamp_decrypt"
}

logging.basicConfig(
    filename=f'solver_{datetime.datetime.today().strftime("%Y_%m_%d")}.log',
    level=logging.DEBUG,
    format='[%(asctime)s] - [%(levelname)s] - %(funcName)s - %(message)s',
    datefmt = '%Y-%m-%d-%H:%M:%S'
)

def handler(signum: "signal._SIGNUM", frame):
    if signal.SIGINT == signum:
        print("Goodbye!")
        exit(0)

def query(con: "psycopg2.connection", sql: str):
    ret = None
    try:
        with con.cursor() as cur:
            cur.execute(sql)
            ret = cur.fetchall()
    except Exception as e:
        logging.error(f"Sql encounter error: {sql}")
    finally:
        return ret

def oracle(con: "psycopg2.connection", enc_var: str, data_type: str) -> str:
    if enc_var.lower() in ["true", "false"]:
        return enc_var
    sql = f"SELECT {data_types[data_type]}('{enc_var}');"
    ret = query(con, sql)
    if ret is None:
        # return None
        exit(-1)
    return ret[0][0]

def get_database_tables(con: "psycopg2.connection") -> list:
    sql = "SELECT tablename FROM pg_catalog.pg_tables WHERE schemaname='public';"
    table_names = query(con, sql)
    if table_names is None:
        exit(-1)
    return [tb_name[0] for tb_name in table_names]

def get_table_info(con: "psycopg2.connection", table_name: str) -> dict:

    def get_user_define_name(col_name: str):
        sql = "SELECT t.typname FROM pg_catalog.pg_type t " \
        "JOIN pg_catalog.pg_attribute a ON a.atttypid = t.oid " \
        "JOIN pg_catalog.pg_class c ON c.oid = a.attrelid " \
        "JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace " \
        f"WHERE n.nspname = 'public' AND c.relname = '{table_name}' AND a.attname = '{col_name}';"
        user_define_type = query(con, sql)
        if user_define_type is None:
            exit(-1)
        return user_define_type[0][0]

    sql = "SELECT column_name, data_type FROM information_schema.columns " \
        f"WHERE table_schema = 'public' AND table_name = '{table_name}';"
    table_infos = query(con, sql)
    if table_infos is None:
        exit(-1)
    return {pair[0]: get_user_define_name(pair[0]) for pair in table_infos if pair[1] == 'USER-DEFINED'}

def establish_table(con: "psycopg2.connection", meta_table_data: dict, var_map: dict, var_rmap: dict):

    def z3_var_ctr(tag: str, type: str):
        ctr = None
        if type == int_type:
            ctr = lambda tag: z3.Int(tag)
        elif type == float_type:
            ctr = lambda tag: z3.Real(tag)
        elif type in [str_type, timestamp_type]:
            ctr = lambda tag: z3.String(tag)
        else:
            logging.error(f"Unknown type: {type}")
            exit(-1)
        return ctr(tag)

    for tb_name, meta_data in meta_table_data.items():
        for col_name, data_type in meta_data.items():

            if data_type == timestamp_type:
                continue

            sql = f"SELECT {col_name} FROM {tb_name};"
            col_data = query(con, sql)
            if col_data is None:
                exit(-1)

            idx = 0
            for line in col_data:
                v = line[0]
                if type(v) == str:
                    if v not in var_map:
                        tmp = z3_var_ctr(f"{tb_name}_{col_name}_{idx}", data_type)
                        idx += 1
                        var_map[v] = tmp
                        var_rmap[str(tmp)] = oracle(con, v, data_type)
                    else:
                        tmp = var_map[v]
                else:
                    logging.warn(f"Some value is not correct: {v}")

is_middle_result = lambda v, var_map: v not in var_map

class OpLog():

    def __init__(self, op: str, vars: tuple, result) -> None:
        # (+ x1 x2 10)
        self.op = op          # plaintext
        self.vars = vars      # tuple of z3.Int or plaintext
        self.result = result  # plaintext or True or False

    def __repr__(self) -> str:
        s = f"({self.op}"
        for v in self.vars:
            s += f" {v}"
        s += f") -> {self.result}"
        return s


def transform(con, raw_line: str, variable_table: dict) -> "OpLog":

    # format: op var1 var2 result
    tokens = raw_line.strip().split()
    op = tokens[0]
    # what's result type ? I need a line type
    result = eval(tokens[-1].capitalize()) if tokens[-1] in ['True', 'False'] else oracle(con, tokens[-1], int_type)
    
    vars = []
    for v in tokens[1:-1]:
        if v not in variable_table:
            # TODO: recognize type
            tmp = oracle(con, v, int_type)
        else:
            tmp = variable_table[v]
        vars.append(tmp)

    return OpLog(op, tuple(vars), result)

def check_op(log: "OpLog", solver: "z3.Solver"):
    compare_op = [">", ">=", "==", "!=", "<=", "<"]

    def check_compare():
        nonlocal log, solver
        if (log.op == '>' and log.result is True) or (log.op == '<=' and log.result is False):
            solver.add(log.vars[0] > log.vars[1])
        elif (log.op == '>=' and log.result is True) or (log.op == '<' and log.result is False):
            solver.add(log.vars[0] >= log.vars[1])
        elif (log.op == '==' and log.result is True) or (log.op == '!=' and log.result is False):
            solver.add(log.vars[0] == log.vars[1])
        elif (log.op == '!=' and log.result is True) or (log.op == '==' and log.result is False):
            solver.add(log.vars[0] != log.vars[1])
        elif (log.op == '<=' and log.result is True) or (log.op == '>' and log.result is False):
            solver.add(log.vars[0] <= log.vars[1])
        elif (log.op == '<' and log.result is True) or (log.op == '>=' and log.result is False):
            solver.add(log.vars[0] < log.vars[1])
        else:
            logging.warning(f"cannot deal this: {log.op}")

    if log.op.lower() in ["+", "sum"]:
        solver.add(z3.Sum(*log.vars) == log.result)
    elif log.op == "-":
        solver.add(log.vars[0] - log.vars[1] == log.result)
    elif log.op == "/":
        solver.add(log.vars[0] / log.vars[1] == log.result)
        solver.add(log.vars[1] != 0)
    elif log.op == "*":
        solver.add(log.vars[0] * log.vars[1] == log.result)
    elif log.op in compare_op:
        check_compare()
    else:
        logging.warning(f"cannot deal this: {log.op}")

def analyze(input_log: "OpLog", logs: list, r_variable_table: dict, ):

    need_check = set()
    candidate = set(input_log.vars)
    need_check.update(candidate)
    
    logging.debug(f"candidate: {candidate}")
    solver = z3.Solver()

    check_op(input_log, solver)
    for log in logs:
        log_candidate = set(log.vars)

        if candidate.intersection(log_candidate):
            need_check.update(log_candidate)
            check_op(log, solver)
    
    logging.debug(f"need check: {need_check}")

    for var in filter(lambda x: type(x) == z3.z3.ExprRef, need_check):
        solver.push()
        solver.add(var != r_variable_table[str(var)])
        if solver.check() == z3.unsat:
            logging.info(f"{solver}")
            return False
        solver.pop()

    return True

def run(integrity_zone: str, privacy_zone: str):
    con: "psycopg2.connection" = psycopg2.connect(
        database='secure_test', 
        user='postgres', 
        password='postgres', 
        host='127.0.0.1', 
        port='5432'
    )
    
    """
    tables: [name1, name2, ...]
    meta_table_data: {
        name1: {
            col_name1: enc_int,
            col_name2: integer,
            ...
        },
        name2: ...
    }
    """
    tables = []
    meta_table_data = {}

    """
    1 database
    n tables 
    ni*mi columns

    variable_table: {
        name1: {
            col_name1: {
                "9gr1yZhfdcr4pO76CbGpSVeEw+B81lk2gyv6fTbmARU=": z3.Int('x1'),
                "enyXzNijLoPyaCoak5JVklAc+IbQ6o1bis+t2aviM9E=": z3.Int('x2'), ...
            }, ...
        }, ...
    }
    cascaded
    or
    variable_table: {
        "9gr1yZhfdcr4pO76CbGpSVeEw+B81lk2gyv6fTbmARU=": z3.Int('x1'),
        "enyXzNijLoPyaCoak5JVklAc+IbQ6o1bis+t2aviM9E=": z3.Int('x2'), ...
    }
    flatted ⭐
    """
    variable_table: dict = {}
    """
    r_variable_table: {
        z3.Int('x1'): 10,
        z3.Int('x2'): 9, ...
    }
    """
    r_variable_table: dict = {}

    logs = []

    tables = get_database_tables(con)
    for tb in tables:
        meta_table_data[tb] = get_table_info(con, tb)
    
    establish_table(con, meta_table_data, variable_table, r_variable_table)
    logging.debug(f"data size = {len(variable_table)}")
    # logging.debug(r_variable_table)
    # return

    with open(integrity_zone, "r") as integrity_fp, open(privacy_zone, "r") as privacy_fp:
        while True:
            if not privacy_fp.readable():
                    # continue
                    break
            line = privacy_fp.readline().strip()
            if line:
                logging.debug(f"raw: {line}")
                new_log = transform(con, line, variable_table)
                logging.debug(f"transform: {new_log}")
                
                result = analyze(new_log, logs, r_variable_table)
                if not result:
                    logging.warning(f"analyze result: Secret exposed!")
                else:
                    logs.append(new_log)
            input("next>")



# python3 log_check_v2.py -i ./integrity_zone.log -p ./privacy_zone.log
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("-i", "--integrity", help="Path of intergrity.log", type=str, required=True)
    parser.add_argument("-p", "--privacy", help="Path of privacy.log", type=str, required=True)
    args = parser.parse_args()

    logging.debug(f"i: {args.integrity}, p: {args.privacy}")

    signal.signal(signal.SIGINT, handler=handler)

    run(args.integrity, args.privacy)

if __name__ == "__main__":

    main()
    
    

